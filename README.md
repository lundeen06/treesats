# TreeSats üõ∞Ô∏èüå≤
## Defending Space Sovereignty

**Satellites that protect themselves: end-to-end autonomous satellite collision avoidance in communication-denied environments**

TreeSats enables satellites to detect collisions, execute evasive maneuvers, and assess threats‚Äîall without GPS or ground contact. Using only star tracker cameras (standard spacecraft hardware), TreeSats provides autonomous protection in contested space.

---

## The Problem

Thousands of satellites orbit Earth today. SpaceX alone plans to deploy **1 million** by 2030. Meanwhile, **GPS and communications jamming** is expanding across Eastern Europe, Southeast Asia, and Myanmar‚Äîaffecting even commercial satellites. Ground station control isn't viable at this scale in contested regions.

Satellites are no longer passive‚Äîthey maneuver unpredictably, creating collision risks with no margin for error.

## The Solution:
<p align="left">
  <img src="https://drive.google.com/uc?export=view&id=1lbUgbUyeI4kUeUHzc2t0AbJ29y34Fm_s" alt="Starguard System Diagram" width="250em"/>
</p>

TreeSats' **Starguard** system provides three autonomous capabilities:

1. **Collision Detection** - YOLOv8 + BoT-SORT identify satellites and debris in star tracker imagery, UKF estimates trajectories from angles-only measurements
   <p align="center">
     <img src="https://drive.google.com/uc?export=view&id=1xzDJ-i59cHXLY0aJ8GwoAdINu9SL0_rB" alt="Detection" width="40%"/>
     <img src="https://drive.google.com/thumbnail?id=1NW5rMCgtGMTp9HBoaMQg_mX1bjjVmRvC&sz=w1000" alt="Collision Avoidance" width="50%"/>
   </p>

2. **Collision Avoidance** - Convex optimization computes fuel-optimal evasive maneuvers for non-adversarial and adversarial satellites
<p align="center">
  <img src="https://drive.google.com/thumbnail?id=1DY_pNTBg9X7kO-Gb5fsW9xsS55nn07S-&sz=w1000" alt="Collision Avoidance" width="60%"/>
  <img src="https://drive.google.com/thumbnail?id=1s6pmjE2kwMOZi4Kas_SFDr-vOzMF5uRe&sz=w1000" alt="Threat Assessment" width="35%"/>
</p>

3. **Threat Assessment** - NVIDIA Cosmos VLM conducts a satellite threat assessment for satellites in close proximity orbits
<p align="center">
  <img src="https://drive.google.com/thumbnail?id=1VvNbrP6w-B9JxoqLWdP5gTR2MLfsx2OF&sz=w1000" alt="Demo 0" width="80%"/>
  <img src="https://drive.google.com/uc?export=view&id=1BDNoNxncAkacbsRdfgB7F8g53OMLWowd" alt="Demo 2" width="80%"/>
</p>

All processing happens onboard using existing star tracker cameras. No GPS. No ground link required.

---

## Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Generate synthetic training data (orbital sim + star tracker images)
python main.py --mode train --duration 0.5 --visualize

# Auto-label the generated images
cd sat/computer_vision
python auto_label.py batch data/images/train/ data/labels/train/

# Train YOLOv8 satellite detector
python train.py --epochs 150 --batch 64

# Run full pipeline (simulate ‚Üí detect ‚Üí track ‚Üí avoid)
cd ../..
python main.py --mode pipeline
```

---

## Key Features

- **Communication-Independent**: Operates without GPS or ground contact using only star tracker imagery
- **Autonomous**: Real-time collision detection, avoidance, and threat assessment without ground intervention
- **Scalable**: GPU acceleration handles 10,000+ satellites simultaneously
- **Mission-Aware**: Fuel-optimal maneuvers via convex optimization

---

## Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| Orbital Propagation | Tensorgator (GPU) | High-fidelity Keplerian mechanics for 10k+ satellites |
| Object Detection | YOLOv8 | Detect satellites/debris in star tracker images |
| Object Tracking | BoT-SORT | Persistent IDs across frames for trajectory extraction |
| State Estimation | Unscented Kalman Filter | Fuse measurements with orbital dynamics |
| Maneuver Planning | CVXPY | Convex optimization for collision avoidance |
| Classification | NVIDIA Cosmos VLM | Identify satellite types and assess threats |

---

## Repository Structure

```
treesats/
‚îú‚îÄ‚îÄ main.py                    # Entry point (train/pipeline modes)
‚îú‚îÄ‚îÄ sim/                       # GPU orbital simulation
‚îÇ   ‚îú‚îÄ‚îÄ simulate.py           # Tensorgator propagation
‚îÇ   ‚îî‚îÄ‚îÄ star_tracker/         # Camera rendering
‚îú‚îÄ‚îÄ sat/
‚îÇ   ‚îú‚îÄ‚îÄ computer_vision/      # YOLOv8 detection + tracking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auto_label.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING.md       # Complete training guide
‚îÇ   ‚îî‚îÄ‚îÄ control/              # Collision avoidance + GNC
‚îú‚îÄ‚îÄ treesats_proximity/        # VLM threat assessment
‚îî‚îÄ‚îÄ flyby_data/               # Test imagery (Cassini, TIE, etc.)
```

---

## Documentation

- **[Training Guide](sat/computer_vision/TRAINING.md)** - YOLOv8 training for satellite detection
- **[Auto-Labeling Guide](sat/computer_vision/AUTO_LABELING.md)** - Automated dataset generation
- **[Presentation Slides](slides/treesats.pdf)** - Full system overview

---

<br>

# Detailed Technical Overview

## How Starguard Works

### 1. Detection Pipeline

**Star trackers** are attitude sensors present on virtually all spacecraft. TreeSats repurposes them for threat detection:

```
Star Tracker Image ‚Üí YOLOv8 Detection ‚Üí BoT-SORT Tracking ‚Üí Bearing Angles
```

- Filters out background stars (known catalog)
- Detects moving objects as bright spots
- Assigns persistent track IDs
- Extracts pixel coordinates ‚Üí elevation/azimuth angles

### 2. Angles-Only Navigation

From sequential star tracker images, TreeSats reconstructs full 6-DOF state:

| Images | Information Extracted |
|--------|---------------------|
| 1 photo | Bearing angles (el, az) |
| 2 photos | Bearing + depth ‚Üí **Position vector** |
| 3 photos | Finite difference ‚Üí **Position + Velocity** |

**Output**: State vector `x = [x, y, z, ·∫ã, ·∫è, ≈º]` in ECI frame

### 3. State Estimation (UKF)

An **Unscented Kalman Filter** fuses two information sources:

- **Dynamics Model**: Keplerian orbital propagation (`M = E - e sin E`)
- **Measurements**: Position/velocity from star tracker angles

This provides filtered, noise-resistant state estimates for collision prediction.

### 4. Collision Detection

Forward-propagate filtered trajectories to compute:

- **Closest approach distance** (miss distance)
- **Time to closest approach**
- **Probability of collision** (from covariance)

If risk exceeds threshold ‚Üí trigger autonomous maneuver.

### 5. Evasive Maneuvers

**Convex optimization** (CVXPY) solves for minimum ŒîV subject to:

- Collision avoidance constraint (minimum safe distance)
- Fuel budget limit
- Thrust magnitude/direction limits
- Mission constraints (maintain orbit parameters)

**Output**: Time-optimal thrust profile for safe evasion.

---

## GPU Orbital Simulation

TreeSats uses **Tensorgator** (GPU-accelerated Keplerian propagator) to simulate 10,000+ satellites:

```python
# Solve Kepler's equation: M = E - e sin E
# Distribute across 10k satellites on CUDA cores
positions, velocities = propagate_constellation(
    n_sats=10000,
    duration_hours=24,
    dt_seconds=10
)
```

**Performance**: 10,000 satellites √ó 8,640 timesteps (24h @ 10s) in seconds on GPU vs. hours on CPU.

---

## Star Tracker Rendering

**Pinhole camera model** generates synthetic 256√ó256 images:

1. Project satellite positions into camera frame (RTN ‚Üí body frame)
2. Apply perspective projection with field-of-view
3. Render as bright dots on black background
4. Save as training images

**Auto-labeling**: Brightness thresholding automatically generates YOLO bounding boxes from ground truth positions‚Äîno manual annotation required.

---

## Computer Vision Pipeline

### Training Workflow

```bash
# 1. Generate synthetic data
python main.py --mode train --duration 0.5 --visualize

# 2. Auto-label (brightness thresholding)
cd sat/computer_vision
python auto_label.py batch data/images/train/ data/labels/train/

# 3. Validate dataset
python prepare_data.py validate

# 4. Train YOLOv8
python train.py --epochs 150 --batch 64 --model yolov8m
```

### Inference

```python
from sat.computer_vision import detect_single, track

# Single image detection
result = detect_single("star_tracker_image.jpg")
print(f"Detected {result['count']} objects")

# Video tracking
results = track("star_tracker_sequence.mp4", tracker="botsort.yaml")
```

**Output**: Bounding boxes + persistent track IDs + pixel coordinates

---

## VLM Threat Assessment

**NVIDIA Cosmos Reason** (served via **vLLM**) classifies satellites from imagery:

```bash
cd treesats_proximity
python assessment.py flyby_data/cassini/cassini.mp4
```

**Identifies**:
- Satellite type (Cassini spacecraft, communications sat, etc.)
- Object class (active satellite vs. debris vs. fairing)
- Threat level based on maneuver capability

**vLLM** provides high-throughput, low-latency inference for the vision-language model, enabling real-time proximity threat assessment onboard satellites.

Supports images, image sequences, and video (mp4/avi/mov).

---

## Demonstration Scenarios

### Chaser-Evader
- **Chaser** actively pursues target
- **Evader** (your satellite) detects and autonomously evades
- Real-time trajectory prediction enables proactive response

### Multi-Object Tracking
- Simultaneous tracking of multiple threats
- Prioritized risk scoring (closest approach, time-to-collision)
- Coordinated maneuvers to avoid multiple objects

### Collision Avoidance
- Forward propagate trajectories
- Predict collisions before they occur
- Compute fuel-optimal avoidance maneuver

---

## Applications

### Commercial Space
- Starlink, OneWeb, and mega-constellations
- Earth observation satellites
- Communications satellites

### National Security
- Reconnaissance satellites in communication-denied regions
- Resilient operations in contested environments
- Autonomous collision detection, avoidance, and threat assessment

### Space Situational Awareness
- Orbital debris tracking
- Traffic management for crowded orbits
- Collision warning systems

---

## Team

- **Sid Anantha** - SpaceX Starship GNC
- **Rahul Ayanampudi** - Northrop Grumman GNC/Physical AI
- **Lundeen Cahilly** - Stanford CS, Incoming GNC @ K2 Space
- **Raj Thapliyal** - Defence Science Org. - Satellite Technology & Research / NUS ML
---

## Roadmap

- [ ] Embedded deployment (spacecraft flight computer)
- [ ] Multi-sensor fusion (star tracker + IMU + magnetometer)
- [ ] Cooperative avoidance (inter-satellite coordination)
- [ ] Hardware-in-the-loop testing
- [ ] Flight software integration

---

<p align="center">
  <strong>TreeSats: Autonomous orbital defense for the modern space domain</strong>
</p>
